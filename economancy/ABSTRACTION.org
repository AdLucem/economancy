
#+title: The Program at an Abstract Level


LOOP:
    1. for player in players: GameMachine --[State]--> Players
    2. for player in players: Player --[Action]--> GameMachine
    3. GameMachine :: State -> [Action] -> State 

* Game Machine
** Earning Phase

This one has only one direct step

GameMachine  -- (State + earning) --> Players

** Investing Phase

this one I have already implemented

** Attacking Phase 

Step 1:
GameMachine -> [State phrase=Attacking AttackerIndex Nothing] -> Players 

Step 2:
for player in players:
  if playerIndex == AttackerIndex:
    attackingCardIndex <- Player (State ...)
    return (Attack attackingCardIndex)
  else:
    return Noop

Step 3: 
phase' -> Defending AttackerIndex (AttackingCard = AttackingCardIndex)
State -> State (phase = phase')

** Defending Phase

Step 1:
GameMachine -> Players 

Step 2:
for player in players:
  if playerIndex != attackerIndex:
    defendingCardIndex <- Player 
    return (Defend defendingCardIndex)
  else:
    return Noop

Step 3:

let (atkPlayer, atkCard) <- Defending atkPlayer __AttackingCard__
 
let (defPlayer, defCards) <- extract defcards, playerIds from Defend action

fight

return (State | players -> all players with appropriate cards fainted) 

** Buy Phase

Step 1:

GameMachine -- (State phase = Buy) --> Players

Step 2:

[cardToBuy] <- Players 

Step 3:

- step 3.1:
for card in shop:
  if number of players buying the card > number of cards:
    card leaves the shop and no player gets it

- step 3.2:
for player in players:
  if card.price <= player coins:
    Player <- Player (cards += card, coins -= card.price)
  else:
    Player (coins = 0)

return State (players <- [Player]


* MDP


#+BEGIN_SRC haskell
policy :: State -> Action

reward :: State -> Reward 

transition :: State -> Action -> State
#+END_SRC

** Transition Function

Although this game is technically a multi-agent system, we'll very crudely approximate a single-agent system by making every other player a part of the environment.

So while from the game system's perspective, it takes a set/unordered list of actions:

#+BEGIN_SRC haskell
gameMachine :: State -> [Action] -> State
#+END_SRC

From the player's perspective, the **transition function** takes only the player's own action.

#+BEGIN_SRC haskell
transition :: State -> Action -> State
#+END_SRC

And this works... how?



* MCTS

Monte Carlo tree search constructs a =Tree= where a node is a (State, Action, Value) tuple. We use the =Data.Tree= library for this.

#+BEGIN_SRC haskell
import Data.Tree 
 
data TreeNode = TreeNode {state  :: State,
                          action :: Action,
                          value  :: Value}

type MCTree := Tree TreeNode
#+END_SRC 

** Step 1: Selection

Start from root =R= and pick a leaf node =L= via one of three methods:

- Via BFS
- Randomly
- Pick best (most promising) child node out of all child nodes

Here, we demonstrate flattening the tree and picking a leaf node from the flattened tree using some given function =heuristic= (that takes a list of nodes and selects one particular node and returns that) 

#+BEGIN_SRC haskell
isLeaf :: MCTree -> Bool
isLeaf (Node _ []) = True 
isLeaf _ = False

selection :: MCTree -> ([MCTree] -> MCTree) -> MCTree
selection root heuristic =
  let 
    allNodes = flatten root
    allLeaves = filter (\x -> isLeaf x) allNodes
  in
    heuristic allLeaves 
#+END_SRC

** Step 2: Expansion

Generate all child nodes of =L= and link them to =L=. Randomly follow one child node.

*** Step 2.1: Generating Search Space

#+BEGIN_SRC haskell
type SearchSpace = [Action]
#+END_SRC

For each state, we need to generate the set of valid moves from that state.

#+BEGIN_SRC haskell
Earning := Noop 

Investing := 
  Invest x; where x <= player.coins

Attacking AttackerIndex _ :=
  if (AttackerIndex == state.playerIndex)
  then Attack x
      where
         (x belongsTo player.cardSet AND
          attack x \= Nothing)
  else Noop

Defending AttackerIndex AttackingCard :=
  if (AttackerIndex == state.playerIndex)
  then Noop 
  else Defend x
    where 
      -- note: we can put another condition here where if
      -- possible, defend x > attack attackingCard
      (x belongsTo player.cardSet AND
       defend x \= nothing)

Buying :=
  if (player.coins > 0) 
  then Buy (Just x)
    where
      (x in state.shop AND
       cost x <= player.coins)
  else Buy Nothing

End _ := Noop 
#+END_SRC

We take the State at the given node and generate a =search space= from it.

#+BEGIN_SRC haskell
genSearchSpace :: TreeNode -> SearchSpace 
genSearchSpace (TreeNode (state _ _)) = getAllValidMoves state 
#+END_SRC

We spin off each element of the search space into its own node and attach it to current node.

#+BEGIN_SRC haskell
expandLeaf :: MCTree -> MCTree 
expandLeaf (Node node children) = 
  let
    searchSpace = genSearchSpace node
    mkChildren = map (\ac -> TreeNode (transition node.state ac) ac (0, 0)) searchSpace   
  in
    Node node mkChildren
#+END_SRC

*** Step 2.2: Randomly Sample from Search Space

We now randomly sample from the children of the given node to get a child node =C=.

#+BEGIN_SRC haskell
randomChild :: MCTree -> MCTree 
randomChild (Node node children) = [random logic]
#+END_SRC

*** Step 2.3: Complete one full playout from =C=


We do this by repeatedly applying =transition state action=

#+BEGIN_SRC haskell

type GameResult = Win | Lose | Draw

-- get phase from MCTree node
state :: MCTree -> Phase

playout :: MCTree -> GameResult
playout MCTree = if (phase MCTree == End _)
  then return result
  else playout (next MCTree) 
#+END_SRC

#+BEGIN_SRC haskell

if node'.state.phase \= End _:
  goto step 3
else:
  state' = transition state action
  node' = TreeNode (state', ...)
#+END_SRC

** Step 3:

Once end state is reached, update =C=, then backpropagate all the way from =C= to root =R=.

* You May Have Noticed That The Above Algorithm Is Stateful

Yes.

We could try running tree search as a list comprehension:

#+BEGIN_SRC haskell

#+END_SRC


